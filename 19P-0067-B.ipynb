{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data\n",
    "data = open(\"Movies_TV.txt\").read()\n",
    "data = data.split('\\n')\n",
    "data.remove(data[0])\n",
    "data.remove(data[-1])\n",
    "data.remove(data[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "y = []\n",
    "for item in data:\n",
    "    _, label, _, text = item.split('\\t')\n",
    "    reviews.append(text)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec = TfidfVectorizer(max_df = 600, min_df = 5, ngram_range = (1,3), max_features = 75)\n",
    "X = vec.fit_transform(reviews)\n",
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'my': 37,\n",
       " 'love': 32,\n",
       " 'film': 17,\n",
       " 'get': 21,\n",
       " 'story': 56,\n",
       " 'great': 23,\n",
       " 'can': 9,\n",
       " 'really': 48,\n",
       " 'as': 3,\n",
       " 'on': 41,\n",
       " 'episode': 16,\n",
       " 'new': 38,\n",
       " 'from': 20,\n",
       " 'what': 68,\n",
       " 'at': 4,\n",
       " 'dvd': 15,\n",
       " 'see': 51,\n",
       " 'that': 57,\n",
       " 'time': 62,\n",
       " 'movie': 36,\n",
       " 'in': 27,\n",
       " 'not': 39,\n",
       " 'for': 19,\n",
       " 'be the': 6,\n",
       " 'of the': 40,\n",
       " 'be not': 5,\n",
       " 'have': 24,\n",
       " 'he': 25,\n",
       " 'so': 54,\n",
       " 'one': 42,\n",
       " 'out': 44,\n",
       " 'but': 7,\n",
       " 'we': 67,\n",
       " 'will': 71,\n",
       " 'there': 58,\n",
       " 'watch': 66,\n",
       " 'lrb': 33,\n",
       " 'rrb': 49,\n",
       " 'would': 73,\n",
       " 'if': 26,\n",
       " 'cinderella': 10,\n",
       " 'she': 53,\n",
       " 'do': 12,\n",
       " 'they': 59,\n",
       " 'with': 72,\n",
       " 'who': 70,\n",
       " 'just': 30,\n",
       " 'it be': 29,\n",
       " 'to the': 63,\n",
       " 'in the': 28,\n",
       " 'do not': 13,\n",
       " 'this movie': 61,\n",
       " 'doctor': 14,\n",
       " 'this be': 60,\n",
       " 'disney': 11,\n",
       " 'some': 55,\n",
       " 'good': 22,\n",
       " 'up': 64,\n",
       " 'all': 1,\n",
       " 'by': 8,\n",
       " 'or': 43,\n",
       " 'you': 74,\n",
       " 'when': 69,\n",
       " 'make': 34,\n",
       " 'about': 0,\n",
       " 'peter': 46,\n",
       " 'pan': 45,\n",
       " 'peter pan': 47,\n",
       " 'very': 65,\n",
       " 'like': 31,\n",
       " 'season': 50,\n",
       " 'series': 52,\n",
       " 'more': 35,\n",
       " 'and the': 2,\n",
       " 'first': 18}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.12181443, 0.        ,\n",
       "        0.127491  ]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainX, testX, trainY, testY = train_test_split(X, y, shuffle = True, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 300)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainX), len(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = SGDClassifier()\n",
    "nbc = GaussianNB()\n",
    "dtc = DecisionTreeClassifier()\n",
    "knnc = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc.fit(trainX, trainY)\n",
    "nbc.fit(trainX, trainY)\n",
    "dtc.fit(trainX, trainY)\n",
    "knnc.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_lc = lc.predict(testX)\n",
    "pred_y_nbc = nbc.predict(testX)\n",
    "pred_y_dtc = dtc.predict(testX)\n",
    "pred_y_knnc = knnc.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "lc_acc = accuracy_score(testY, pred_y_lc)\n",
    "nbc_acc = accuracy_score(testY, pred_y_nbc)\n",
    "dtc_acc = accuracy_score(testY, pred_y_dtc)\n",
    "knnc_acc = accuracy_score(testY, pred_y_knnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Classifier:  0.8333333333333334\n",
      "Naive Bayes Classifier:  0.58\n",
      "Decision Tree Classifier:  0.75\n",
      "KNN Classifier:  0.8\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Classifier: \", lc_acc)\n",
    "print(\"Naive Bayes Classifier: \", nbc_acc)\n",
    "print(\"Decision Tree Classifier: \", dtc_acc)\n",
    "print(\"KNN Classifier: \", knnc_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4,   2,  26],\n",
       "       [  2,   1,  15],\n",
       "       [  2,   1, 247]], dtype=int64)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(testY, pred_y_lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 16,   6,  10],\n",
       "       [  4,  11,   3],\n",
       "       [ 60,  43, 147]], dtype=int64)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(testY,  pred_y_nbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9,   3,  20],\n",
       "       [  4,   2,  12],\n",
       "       [ 22,  14, 214]], dtype=int64)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(testY, pred_y_dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3,   1,  28],\n",
       "       [  0,   2,  16],\n",
       "       [  9,   7, 234]], dtype=int64)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(testY, pred_y_knnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Classifier:\n",
      "Macro:Percison,recall,fscore (0.5358796296296297, 0.38951851851851854, 0.4030415680973302, None)\n",
      "Micro:Percison,recall,fscore (0.84, 0.84, 0.8399999999999999, None)\n",
      "Weighted:Percison,recall,fscore (0.7830324074074073, 0.84, 0.7919675566069618, None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "print(\"Linear Classifier:\")\n",
    "Macro=precision_recall_fscore_support(testY, pred_y_lc, average='macro')\n",
    "Micro=precision_recall_fscore_support(testY, pred_y_lc, average='micro')\n",
    "Weighted=precision_recall_fscore_support(testY, pred_y_lc, average='weighted')\n",
    "print('Macro:Percison,recall,fscore',Macro)\n",
    "print('Micro:Percison,recall,fscore',Micro)\n",
    "print('Weighted:Percison,recall,fscore',Weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier:\n",
      "Macro:Percison,recall,fscore (0.43402777777777773, 0.5663703703703704, 0.4282795794990917, None)\n",
      "Micro:Percison,recall,fscore (0.58, 0.58, 0.58, None)\n",
      "Weighted:Percison,recall,fscore (0.7979583333333333, 0.58, 0.6449602430090235, None)\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes Classifier:\")\n",
    "Macro=precision_recall_fscore_support(testY,pred_y_nbc, average='macro')\n",
    "Micro=precision_recall_fscore_support(testY,pred_y_nbc, average='micro')\n",
    "Weighted=precision_recall_fscore_support(testY,pred_y_nbc, average='weighted')\n",
    "print('Macro:Percison,recall,fscore',Macro)\n",
    "print('Micro:Percison,recall,fscore',Micro)\n",
    "print('Weighted:Percison,recall,fscore',Weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier:\n",
      "Macro:Percison,recall,fscore (0.4107749047415286, 0.41612037037037036, 0.41322268344415675, None)\n",
      "Micro:Percison,recall,fscore (0.75, 0.75, 0.75, None)\n",
      "Weighted:Percison,recall,fscore (0.7586766102247489, 0.75, 0.7542292244097731, None)\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Classifier:\")\n",
    "Macro=precision_recall_fscore_support(testY,pred_y_dtc, average='macro')\n",
    "Micro=precision_recall_fscore_support(testY,pred_y_dtc, average='micro')\n",
    "Weighted=precision_recall_fscore_support(testY,pred_y_dtc, average='weighted')\n",
    "print('Macro:Percison,recall,fscore',Macro)\n",
    "print('Micro:Percison,recall,fscore',Micro)\n",
    "print('Weighted:Percison,recall,fscore',Weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classifier:\n",
      "Macro:Percison,recall,fscore (0.4305755395683453, 0.38028703703703703, 0.3885281385281385, None)\n",
      "Micro:Percison,recall,fscore (0.7966666666666666, 0.7966666666666666, 0.7966666666666665, None)\n",
      "Weighted:Percison,recall,fscore (0.74010551558753, 0.7966666666666666, 0.7617532467532467, None)\n"
     ]
    }
   ],
   "source": [
    "print(\"KNN Classifier:\")\n",
    "Macro=precision_recall_fscore_support(testY,pred_y_knnc, average='macro')\n",
    "Micro=precision_recall_fscore_support(testY,pred_y_knnc, average='micro')\n",
    "Weighted=precision_recall_fscore_support(testY,pred_y_knnc, average='weighted')\n",
    "print('Macro:Percison,recall,fscore',Macro)\n",
    "print('Micro:Percison,recall,fscore',Micro)\n",
    "print('Weighted:Percison,recall,fscore',Weighted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
